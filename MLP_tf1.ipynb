{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6cc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5454abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ac0bf1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bd306755",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.reshape(X_train, (-1, 28 * 28))\n",
    "X_train = tf.cast(X_train, tf.float32) / 255.\n",
    "\n",
    "X_test = tf.reshape(X_test, (-1, 28 * 28))\n",
    "X_test = tf.cast(X_test, tf.float32) / 255.\n",
    "\n",
    "y_train = tf.cast(y_train, tf.int64)\n",
    "y_test = tf.cast(y_test, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576150a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(tf.reshape(X_train[0], (28, 28)), cmap='gray')\n",
    "plt.title(f\"Label: {y_train[0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5ba3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainDataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)\n",
    "testDataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784) (128,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 11:58:00.579362: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for X, y in trainDataset.take(1):\n",
    "\tprint(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b805d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 11:58:02.052079: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-01 11:58:04.399723: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-01 11:58:09.915702: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-01 11:58:19.821228: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-01 11:58:37.937719: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "output_size = 10\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal((input_size, hidden_size1), 0, 1))\n",
    "W2 = tf.Variable(tf.random.normal((hidden_size1, hidden_size2), 0, 1))\n",
    "W3 = tf.Variable(tf.random.normal((hidden_size2, output_size), 0, 1))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros((hidden_size1)))\n",
    "b2 = tf.Variable(tf.zeros((hidden_size2)))\n",
    "b3 = tf.Variable(tf.zeros((output_size)))\n",
    "\n",
    "parameters = [W1, W2, W3, b1, b2, b3]\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "\tfor X, y in trainDataset:\n",
    "\t\twith tf.GradientTape() as t:\n",
    "\t\t\ty_hat = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\t\t\ty_hat = tf.nn.relu(tf.matmul(y_hat, W2) + b2) \n",
    "\t\t\ty_hat = tf.matmul(y_hat, W3) + b3\n",
    "\t\t\t# y_hat = tf.argmax(y_hat, axis=1)\n",
    "\t\t\tloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_hat, labels=y))\n",
    "\t\t\t# loss = tf.reduce_mean((y_hat - y) ** 2)\n",
    "\t\t\n",
    "\t\tgradients = t.gradient(loss, parameters)\n",
    "\t\t# for i in range(len(parameters)):\n",
    "\t\t#     parameters[i].assign_sub(lr * gradients[i])\n",
    "\t\tfor param, grad in zip(parameters, gradients):\n",
    "\t\t\tparam.assign_sub(lr * grad)\n",
    "\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 143.7115 | Train Acc: 0.6042 | Test Loss: 56.9982 | Test Acc: 0.7546\n",
      "Epoch  2 | Train Loss: 49.4619 | Train Acc: 0.7784 | Test Loss: 37.6840 | Test Acc: 0.8130\n",
      "Epoch  3 | Train Loss: 35.7634 | Train Acc: 0.8151 | Test Loss: 29.7858 | Test Acc: 0.8308\n",
      "Epoch  4 | Train Loss: 28.6735 | Train Acc: 0.8331 | Test Loss: 24.9029 | Test Acc: 0.8430\n",
      "Epoch  5 | Train Loss: 24.0959 | Train Acc: 0.8442 | Test Loss: 21.5862 | Test Acc: 0.8517\n",
      "Epoch  6 | Train Loss: 20.8479 | Train Acc: 0.8524 | Test Loss: 19.2225 | Test Acc: 0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 11:59:10.860233: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 18.3573 | Train Acc: 0.8595 | Test Loss: 17.4369 | Test Acc: 0.8653\n",
      "Epoch  8 | Train Loss: 16.4426 | Train Acc: 0.8645 | Test Loss: 16.0006 | Test Acc: 0.8674\n",
      "Epoch  9 | Train Loss: 14.8788 | Train Acc: 0.8691 | Test Loss: 14.6583 | Test Acc: 0.8709\n",
      "Epoch 10 | Train Loss: 13.5764 | Train Acc: 0.8725 | Test Loss: 13.6157 | Test Acc: 0.8752\n",
      "Epoch 11 | Train Loss: 12.4681 | Train Acc: 0.8754 | Test Loss: 12.7721 | Test Acc: 0.8765\n",
      "Epoch 12 | Train Loss: 11.5120 | Train Acc: 0.8786 | Test Loss: 11.9014 | Test Acc: 0.8793\n",
      "Epoch 13 | Train Loss: 10.7005 | Train Acc: 0.8805 | Test Loss: 11.2498 | Test Acc: 0.8827\n",
      "Epoch 14 | Train Loss: 9.9893 | Train Acc: 0.8828 | Test Loss: 10.7391 | Test Acc: 0.8831\n",
      "Epoch 15 | Train Loss: 9.3454 | Train Acc: 0.8851 | Test Loss: 10.1294 | Test Acc: 0.8844\n",
      "Epoch 16 | Train Loss: 8.7972 | Train Acc: 0.8866 | Test Loss: 9.6673 | Test Acc: 0.8863\n",
      "Epoch 17 | Train Loss: 8.3084 | Train Acc: 0.8880 | Test Loss: 9.1993 | Test Acc: 0.8870\n",
      "Epoch 18 | Train Loss: 7.8575 | Train Acc: 0.8900 | Test Loss: 8.7962 | Test Acc: 0.8887\n",
      "Epoch 19 | Train Loss: 7.4495 | Train Acc: 0.8908 | Test Loss: 8.4596 | Test Acc: 0.8878\n",
      "Epoch 20 | Train Loss: 7.0891 | Train Acc: 0.8930 | Test Loss: 8.1332 | Test Acc: 0.8894\n",
      "Epoch 21 | Train Loss: 6.7556 | Train Acc: 0.8933 | Test Loss: 7.8673 | Test Acc: 0.8891\n",
      "Epoch 22 | Train Loss: 6.4454 | Train Acc: 0.8951 | Test Loss: 7.5920 | Test Acc: 0.8889\n",
      "Epoch 23 | Train Loss: 6.1522 | Train Acc: 0.8951 | Test Loss: 7.2801 | Test Acc: 0.8908\n",
      "Epoch 24 | Train Loss: 5.8846 | Train Acc: 0.8965 | Test Loss: 7.1002 | Test Acc: 0.8900\n",
      "Epoch 25 | Train Loss: 5.6347 | Train Acc: 0.8971 | Test Loss: 6.8716 | Test Acc: 0.8885\n",
      "Epoch 26 | Train Loss: 5.4142 | Train Acc: 0.8970 | Test Loss: 6.5972 | Test Acc: 0.8914\n",
      "Epoch 27 | Train Loss: 5.1948 | Train Acc: 0.8987 | Test Loss: 6.5636 | Test Acc: 0.8896\n",
      "Epoch 28 | Train Loss: 5.0091 | Train Acc: 0.8993 | Test Loss: 6.2456 | Test Acc: 0.8912\n",
      "Epoch 29 | Train Loss: 4.8180 | Train Acc: 0.9000 | Test Loss: 6.0386 | Test Acc: 0.8910\n",
      "Epoch 30 | Train Loss: 4.6471 | Train Acc: 0.9012 | Test Loss: 5.8716 | Test Acc: 0.8918\n",
      "Epoch 31 | Train Loss: 4.4788 | Train Acc: 0.9015 | Test Loss: 5.7469 | Test Acc: 0.8902\n",
      "Epoch 32 | Train Loss: 4.3277 | Train Acc: 0.9015 | Test Loss: 5.5289 | Test Acc: 0.8918\n",
      "Epoch 33 | Train Loss: 4.1740 | Train Acc: 0.9020 | Test Loss: 5.3475 | Test Acc: 0.8923\n",
      "Epoch 34 | Train Loss: 4.0495 | Train Acc: 0.9027 | Test Loss: 5.1860 | Test Acc: 0.8930\n",
      "Epoch 35 | Train Loss: 3.9221 | Train Acc: 0.9026 | Test Loss: 5.0628 | Test Acc: 0.8934\n",
      "Epoch 36 | Train Loss: 3.7946 | Train Acc: 0.9037 | Test Loss: 4.9488 | Test Acc: 0.8915\n",
      "Epoch 37 | Train Loss: 3.6753 | Train Acc: 0.9035 | Test Loss: 4.8530 | Test Acc: 0.8918\n",
      "Epoch 38 | Train Loss: 3.5694 | Train Acc: 0.9032 | Test Loss: 4.6749 | Test Acc: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 11:59:51.682402: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 3.4679 | Train Acc: 0.9045 | Test Loss: 4.6926 | Test Acc: 0.8915\n",
      "Epoch 40 | Train Loss: 3.3592 | Train Acc: 0.9040 | Test Loss: 4.5144 | Test Acc: 0.8932\n",
      "Epoch 41 | Train Loss: 3.2684 | Train Acc: 0.9053 | Test Loss: 4.3761 | Test Acc: 0.8938\n",
      "Epoch 42 | Train Loss: 3.1765 | Train Acc: 0.9052 | Test Loss: 4.2791 | Test Acc: 0.8945\n",
      "Epoch 43 | Train Loss: 3.0854 | Train Acc: 0.9055 | Test Loss: 4.2928 | Test Acc: 0.8919\n",
      "Epoch 44 | Train Loss: 3.0079 | Train Acc: 0.9061 | Test Loss: 4.0976 | Test Acc: 0.8941\n",
      "Epoch 45 | Train Loss: 2.9329 | Train Acc: 0.9044 | Test Loss: 4.0417 | Test Acc: 0.8933\n",
      "Epoch 46 | Train Loss: 2.8517 | Train Acc: 0.9051 | Test Loss: 3.8979 | Test Acc: 0.8958\n",
      "Epoch 47 | Train Loss: 2.7721 | Train Acc: 0.9058 | Test Loss: 3.8225 | Test Acc: 0.8954\n",
      "Epoch 48 | Train Loss: 2.7039 | Train Acc: 0.9060 | Test Loss: 3.6991 | Test Acc: 0.8973\n",
      "Epoch 49 | Train Loss: 2.6365 | Train Acc: 0.9065 | Test Loss: 3.6635 | Test Acc: 0.8961\n",
      "Epoch 50 | Train Loss: 2.5708 | Train Acc: 0.9060 | Test Loss: 3.6201 | Test Acc: 0.8945\n"
     ]
    }
   ],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "output_size = 10\n",
    "\n",
    "# 权重和偏置初始化\n",
    "W1 = tf.Variable(tf.random.normal((input_size, hidden_size1), 0, 1))\n",
    "W2 = tf.Variable(tf.random.normal((hidden_size1, hidden_size2), 0, 1))\n",
    "W3 = tf.Variable(tf.random.normal((hidden_size2, output_size), 0, 1))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros((hidden_size1)))\n",
    "b2 = tf.Variable(tf.zeros((hidden_size2)))\n",
    "b3 = tf.Variable(tf.zeros((output_size)))\n",
    "\n",
    "parameters = [W1, W2, W3, b1, b2, b3]\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\t# === Train phase ===\n",
    "\ttrain_loss_sum = 0.0\n",
    "\ttrain_correct = 0\n",
    "\ttrain_total = 0\n",
    "\t\n",
    "\tfor X, y in trainDataset:\n",
    "\t\twith tf.GradientTape() as t:\n",
    "\t\t\t# 前向传播\n",
    "\t\t\ty_hat = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\t\t\ty_hat = tf.nn.relu(tf.matmul(y_hat, W2) + b2) \n",
    "\t\t\tlogits = tf.matmul(y_hat, W3) + b3\n",
    "\n",
    "\t\t\t# 损失\n",
    "\t\t\tloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "\t\t# 梯度更新\n",
    "\t\tgradients = t.gradient(loss, parameters)\n",
    "\t\tfor param, grad in zip(parameters, gradients):\n",
    "\t\t\tparam.assign_sub(lr * grad)\n",
    "\n",
    "\t\t# 累积训练指标\n",
    "\t\ttrain_loss_sum += loss.numpy() * X.shape[0]\n",
    "\t\tpreds = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "\t\ttrain_correct += tf.reduce_sum(tf.cast(preds == y, tf.int32)).numpy()\n",
    "\t\ttrain_total += X.shape[0]\n",
    "\n",
    "\t# === Test phase ===\n",
    "\ttest_loss_sum = 0.0\n",
    "\ttest_correct = 0\n",
    "\ttest_total = 0\n",
    "\n",
    "\tfor X, y in testDataset:\n",
    "\t\t# 前向传播\n",
    "\t\ty_hat = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\t\ty_hat = tf.nn.relu(tf.matmul(y_hat, W2) + b2) \n",
    "\t\tlogits = tf.matmul(y_hat, W3) + b3\n",
    "\n",
    "\t\tloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "\t\ttest_loss_sum += loss.numpy() * X.shape[0]\n",
    "\t\tpreds = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "\t\ttest_correct += tf.reduce_sum(tf.cast(preds == y, tf.int32)).numpy()\n",
    "\t\ttest_total += X.shape[0]\n",
    "\n",
    "\t# === 打印每个 epoch 的结果 ===\n",
    "\tprint(f\"Epoch {epoch + 1:2d} | \"\n",
    "\t\t  f\"Train Loss: {train_loss_sum / train_total:.4f} | \"\n",
    "\t\t  f\"Train Acc: {train_correct / train_total:.4f} | \"\n",
    "\t\t  f\"Test Loss: {test_loss_sum / test_total:.4f} | \"\n",
    "\t\t  f\"Test Acc: {test_correct / test_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 138.1181 | Train Acc: 0.6479 | Test Loss: 59.0269 | Test Acc: 0.7887\n",
      "Epoch  2 | Train Loss: 50.7567 | Train Acc: 0.8039 | Test Loss: 41.3992 | Test Acc: 0.8296\n",
      "Epoch  3 | Train Loss: 37.4895 | Train Acc: 0.8357 | Test Loss: 33.0382 | Test Acc: 0.8491\n",
      "Epoch  4 | Train Loss: 30.6379 | Train Acc: 0.8515 | Test Loss: 28.4653 | Test Acc: 0.8569\n",
      "Epoch  5 | Train Loss: 26.0479 | Train Acc: 0.8619 | Test Loss: 25.0861 | Test Acc: 0.8635\n",
      "Epoch  6 | Train Loss: 22.8123 | Train Acc: 0.8702 | Test Loss: 22.7230 | Test Acc: 0.8684\n",
      "Epoch  7 | Train Loss: 20.2887 | Train Acc: 0.8754 | Test Loss: 20.7247 | Test Acc: 0.8746\n",
      "Epoch  8 | Train Loss: 18.3307 | Train Acc: 0.8817 | Test Loss: 19.1012 | Test Acc: 0.8776\n",
      "Epoch  9 | Train Loss: 16.7318 | Train Acc: 0.8852 | Test Loss: 18.1170 | Test Acc: 0.8814\n",
      "Epoch 10 | Train Loss: 15.4007 | Train Acc: 0.8889 | Test Loss: 16.8064 | Test Acc: 0.8862\n",
      "Epoch 11 | Train Loss: 14.2713 | Train Acc: 0.8928 | Test Loss: 15.8971 | Test Acc: 0.8897\n",
      "Epoch 12 | Train Loss: 13.2787 | Train Acc: 0.8948 | Test Loss: 15.3016 | Test Acc: 0.8884\n",
      "Epoch 13 | Train Loss: 12.3882 | Train Acc: 0.8971 | Test Loss: 14.5446 | Test Acc: 0.8903\n",
      "Epoch 14 | Train Loss: 11.6128 | Train Acc: 0.8993 | Test Loss: 13.6254 | Test Acc: 0.8938\n",
      "Epoch 15 | Train Loss: 10.9424 | Train Acc: 0.9007 | Test Loss: 13.1839 | Test Acc: 0.8933\n",
      "Epoch 16 | Train Loss: 10.3015 | Train Acc: 0.9030 | Test Loss: 12.4529 | Test Acc: 0.8950\n",
      "Epoch 17 | Train Loss: 9.7685 | Train Acc: 0.9044 | Test Loss: 12.2321 | Test Acc: 0.8970\n",
      "Epoch 18 | Train Loss: 9.2767 | Train Acc: 0.9062 | Test Loss: 11.6205 | Test Acc: 0.8969\n",
      "Epoch 19 | Train Loss: 8.7982 | Train Acc: 0.9075 | Test Loss: 11.1435 | Test Acc: 0.8991\n",
      "Epoch 20 | Train Loss: 8.4181 | Train Acc: 0.9097 | Test Loss: 10.7438 | Test Acc: 0.8989\n",
      "Epoch 21 | Train Loss: 8.0280 | Train Acc: 0.9101 | Test Loss: 10.4036 | Test Acc: 0.8997\n",
      "Epoch 22 | Train Loss: 7.6783 | Train Acc: 0.9110 | Test Loss: 10.2125 | Test Acc: 0.8981\n",
      "Epoch 23 | Train Loss: 7.3518 | Train Acc: 0.9130 | Test Loss: 9.8115 | Test Acc: 0.8994\n",
      "Epoch 24 | Train Loss: 7.0592 | Train Acc: 0.9136 | Test Loss: 9.5113 | Test Acc: 0.9012\n",
      "Epoch 25 | Train Loss: 6.7835 | Train Acc: 0.9152 | Test Loss: 9.2522 | Test Acc: 0.9020\n",
      "Epoch 26 | Train Loss: 6.5462 | Train Acc: 0.9152 | Test Loss: 8.9630 | Test Acc: 0.9023\n",
      "Epoch 27 | Train Loss: 6.3030 | Train Acc: 0.9165 | Test Loss: 8.6808 | Test Acc: 0.9031\n",
      "Epoch 28 | Train Loss: 6.0841 | Train Acc: 0.9177 | Test Loss: 8.5405 | Test Acc: 0.9030\n",
      "Epoch 29 | Train Loss: 5.8702 | Train Acc: 0.9180 | Test Loss: 8.3320 | Test Acc: 0.9032\n",
      "Epoch 30 | Train Loss: 5.6730 | Train Acc: 0.9182 | Test Loss: 7.9856 | Test Acc: 0.9037\n",
      "Epoch 31 | Train Loss: 5.4892 | Train Acc: 0.9188 | Test Loss: 7.7877 | Test Acc: 0.9054\n",
      "Epoch 32 | Train Loss: 5.2957 | Train Acc: 0.9201 | Test Loss: 7.6818 | Test Acc: 0.9053\n",
      "Epoch 33 | Train Loss: 5.1385 | Train Acc: 0.9206 | Test Loss: 7.4639 | Test Acc: 0.9062\n",
      "Epoch 34 | Train Loss: 4.9818 | Train Acc: 0.9210 | Test Loss: 7.2757 | Test Acc: 0.9065\n",
      "Epoch 35 | Train Loss: 4.8440 | Train Acc: 0.9219 | Test Loss: 7.0136 | Test Acc: 0.9080\n",
      "Epoch 36 | Train Loss: 4.6851 | Train Acc: 0.9217 | Test Loss: 7.0095 | Test Acc: 0.9071\n",
      "Epoch 37 | Train Loss: 4.5731 | Train Acc: 0.9226 | Test Loss: 6.8897 | Test Acc: 0.9064\n",
      "Epoch 38 | Train Loss: 4.4305 | Train Acc: 0.9237 | Test Loss: 6.6989 | Test Acc: 0.9079\n",
      "Epoch 39 | Train Loss: 4.3090 | Train Acc: 0.9229 | Test Loss: 6.6094 | Test Acc: 0.9064\n",
      "Epoch 40 | Train Loss: 4.1981 | Train Acc: 0.9236 | Test Loss: 6.4844 | Test Acc: 0.9074\n",
      "Epoch 41 | Train Loss: 4.0785 | Train Acc: 0.9231 | Test Loss: 6.2474 | Test Acc: 0.9093\n",
      "Epoch 42 | Train Loss: 3.9719 | Train Acc: 0.9242 | Test Loss: 6.2445 | Test Acc: 0.9058\n",
      "Epoch 43 | Train Loss: 3.8585 | Train Acc: 0.9250 | Test Loss: 6.1150 | Test Acc: 0.9070\n",
      "Epoch 44 | Train Loss: 3.7657 | Train Acc: 0.9250 | Test Loss: 5.9079 | Test Acc: 0.9109\n",
      "Epoch 45 | Train Loss: 3.6765 | Train Acc: 0.9251 | Test Loss: 5.8387 | Test Acc: 0.9095\n",
      "Epoch 46 | Train Loss: 3.5931 | Train Acc: 0.9256 | Test Loss: 5.7545 | Test Acc: 0.9090\n",
      "Epoch 47 | Train Loss: 3.5090 | Train Acc: 0.9256 | Test Loss: 5.6318 | Test Acc: 0.9096\n",
      "Epoch 48 | Train Loss: 3.4157 | Train Acc: 0.9261 | Test Loss: 5.5195 | Test Acc: 0.9106\n",
      "Epoch 49 | Train Loss: 3.3354 | Train Acc: 0.9261 | Test Loss: 5.3980 | Test Acc: 0.9109\n",
      "Epoch 50 | Train Loss: 3.2655 | Train Acc: 0.9268 | Test Loss: 5.4864 | Test Acc: 0.9089\n"
     ]
    }
   ],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "output_size = 10\n",
    "\n",
    "# 权重和偏置初始化\n",
    "W1 = tf.Variable(tf.random.normal((input_size, hidden_size1), 0, 1))\n",
    "W2 = tf.Variable(tf.random.normal((hidden_size1, hidden_size2), 0, 1))\n",
    "W3 = tf.Variable(tf.random.normal((hidden_size2, output_size), 0, 1))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros((hidden_size1)))\n",
    "b2 = tf.Variable(tf.zeros((hidden_size2)))\n",
    "b3 = tf.Variable(tf.zeros((output_size)))\n",
    "\n",
    "parameters = [W1, W2, W3, b1, b2, b3]\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\t# === Train phase ===\n",
    "\ttrain_loss_sum = 0.0\n",
    "\ttrain_correct = 0\n",
    "\ttrain_total = 0\n",
    "\t\n",
    "\tfor X, y in trainDataset:\n",
    "\t\twith tf.GradientTape() as t:\n",
    "\t\t\t# 前向传播\n",
    "\t\t\ty_hat = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\t\t\ty_hat = tf.nn.relu(tf.matmul(y_hat, W2) + b2) \n",
    "\t\t\tlogits = tf.matmul(y_hat, W3) + b3\n",
    "\n",
    "\t\t\t# 损失\n",
    "\t\t\tloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "\t\t# 梯度更新\n",
    "\t\tgradients = t.gradient(loss, parameters)\n",
    "\t\tfor param, grad in zip(parameters, gradients):\n",
    "\t\t\tparam.assign_sub(lr * grad)\n",
    "\n",
    "\t\t# 累积训练指标\n",
    "\t\ttrain_loss_sum += loss.numpy() * X.shape[0]\n",
    "\t\tpreds = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "\t\ttrain_correct += tf.reduce_sum(tf.cast(preds == y, tf.int32)).numpy()\n",
    "\t\ttrain_total += X.shape[0]\n",
    "\n",
    "\t# === Test phase ===\n",
    "\ttest_loss_sum = 0.0\n",
    "\ttest_correct = 0\n",
    "\ttest_total = 0\n",
    "\n",
    "\tfor X, y in testDataset:\n",
    "\t\t# 前向传播\n",
    "\t\ty_hat = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\t\ty_hat = tf.nn.relu(tf.matmul(y_hat, W2) + b2) \n",
    "\t\tlogits = tf.matmul(y_hat, W3) + b3\n",
    "\n",
    "\t\tloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "\t\ttest_loss_sum += loss.numpy() * X.shape[0]\n",
    "\t\tpreds = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "\t\ttest_correct += tf.reduce_sum(tf.cast(preds == y, tf.int32)).numpy()\n",
    "\t\ttest_total += X.shape[0]\n",
    "\n",
    "\t# === 打印每个 epoch 的结果 ===\n",
    "\tprint(f\"Epoch {epoch + 1:2d} | \"\n",
    "\t\t  f\"Train Loss: {train_loss_sum / train_total:.4f} | \"\n",
    "\t\t  f\"Train Acc: {train_correct / train_total:.4f} | \"\n",
    "\t\t  f\"Test Loss: {test_loss_sum / test_total:.4f} | \"\n",
    "\t\t  f\"Test Acc: {test_correct / test_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca9ee666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b742a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_dataset = Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size=256)\n",
    "test_dataset = Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aab31a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffa336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28) (256,)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_dataset.take(1):\n",
    "\tprint(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "527ab176",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7cea3a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_67\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_67\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_241 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_242 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_243 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_241 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_242 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_243 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.6238 - val_accuracy: 0.9565 - val_loss: 0.1508\n",
      "Epoch 2/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1363 - val_accuracy: 0.9670 - val_loss: 0.1088\n",
      "Epoch 3/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0825 - val_accuracy: 0.9712 - val_loss: 0.0907\n",
      "Epoch 4/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0626 - val_accuracy: 0.9773 - val_loss: 0.0751\n",
      "Epoch 5/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0425 - val_accuracy: 0.9778 - val_loss: 0.0714\n",
      "Epoch 6/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0349 - val_accuracy: 0.9794 - val_loss: 0.0676\n",
      "Epoch 7/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0245 - val_accuracy: 0.9774 - val_loss: 0.0748\n",
      "Epoch 8/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0201 - val_accuracy: 0.9797 - val_loss: 0.0652\n",
      "Epoch 9/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0148 - val_accuracy: 0.9796 - val_loss: 0.0682\n",
      "Epoch 10/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0116 - val_accuracy: 0.9764 - val_loss: 0.0832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30bacff40>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义 MLP 模型，使用tf.keras.Sequential\n",
    "\n",
    "model1 = tf.keras.Sequential(\n",
    "\t[\n",
    "\t tf.keras.layers.Dense(hidden_size1, activation='relu', input_shape=(input_size, )),\n",
    "\t tf.keras.layers.Dense(hidden_size2, activation='relu'),\n",
    "\t tf.keras.layers.Dense(output_size, activation='softmax')  \n",
    "\t]\n",
    ")\n",
    "\n",
    "model1.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# X_train = tf.cast(tf.reshape(X_train, (-1, 28*28)), tf.float32) / 255.0\n",
    "# X_test = tf.cast(tf.reshape(X_test, (-1, 28*28)), tf.float32) / 255.0\n",
    "# X_train = X_train.reshape(-1, 28 * 28).astype('float32') / 255.0  # 展平28x28图片并归一化\n",
    "# X_test = X_test.reshape(-1, 28 * 28).astype('float32') / 255.0    # 同样处理测试数据\n",
    "model1.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2eeac891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_80\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_80\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_83 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_11 (\u001b[38;5;33mMLP\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │       \u001b[38;5;34m235,146\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 - 1s - 5ms/step - accuracy: 0.9049 - loss: 0.3366 - val_accuracy: 0.9517 - val_loss: 0.1648\n",
      "Epoch 2/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9631 - loss: 0.1264 - val_accuracy: 0.9680 - val_loss: 0.1047\n",
      "Epoch 3/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9746 - loss: 0.0855 - val_accuracy: 0.9726 - val_loss: 0.0877\n",
      "Epoch 4/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9812 - loss: 0.0622 - val_accuracy: 0.9763 - val_loss: 0.0757\n",
      "Epoch 5/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9858 - loss: 0.0465 - val_accuracy: 0.9771 - val_loss: 0.0747\n",
      "Epoch 6/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9886 - loss: 0.0377 - val_accuracy: 0.9753 - val_loss: 0.0765\n",
      "Epoch 7/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9923 - loss: 0.0275 - val_accuracy: 0.9788 - val_loss: 0.0688\n",
      "Epoch 8/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9938 - loss: 0.0217 - val_accuracy: 0.9775 - val_loss: 0.0739\n",
      "Epoch 9/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9946 - loss: 0.0180 - val_accuracy: 0.9781 - val_loss: 0.0767\n",
      "Epoch 10/10\n",
      "235/235 - 1s - 2ms/step - accuracy: 0.9964 - loss: 0.0135 - val_accuracy: 0.9781 - val_loss: 0.0735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30d55fe80>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义 MLP 模型，使用 tf.keras.Model\n",
    "class MLP(tf.keras.Model):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(MLP, self).__init__()\n",
    "\t\tself.layer1 = tf.keras.layers.Dense(hidden_size1, activation='relu')\n",
    "\t\tself.layer2 = tf.keras.layers.Dense(hidden_size2, activation='relu')\n",
    "\t\tself.layer3 = tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "\t\n",
    "\tdef call(self, x):\n",
    "\t\tx = self.layer1(x)\n",
    "\t\tx = self.layer2(x)\n",
    "\t\tx = self.layer3(x)\n",
    "\n",
    "\t\treturn x \n",
    "input = tf.keras.layers.Input(shape=(input_size, ))\n",
    "output = MLP()(input)\n",
    "model2 = tf.keras.Model(input, output)\n",
    "\n",
    "model2.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5914652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_81\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_81\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_250 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_251 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_252 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_84 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_250 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_251 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_252 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.6255 - val_accuracy: 0.9527 - val_loss: 0.1578\n",
      "Epoch 2/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1382 - val_accuracy: 0.9656 - val_loss: 0.1078\n",
      "Epoch 3/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.0859 - val_accuracy: 0.9724 - val_loss: 0.0897\n",
      "Epoch 4/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0617 - val_accuracy: 0.9777 - val_loss: 0.0753\n",
      "Epoch 5/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0467 - val_accuracy: 0.9775 - val_loss: 0.0729\n",
      "Epoch 6/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0371 - val_accuracy: 0.9771 - val_loss: 0.0725\n",
      "Epoch 7/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0271 - val_accuracy: 0.9796 - val_loss: 0.0690\n",
      "Epoch 8/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0196 - val_accuracy: 0.9793 - val_loss: 0.0752\n",
      "Epoch 9/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0161 - val_accuracy: 0.9774 - val_loss: 0.0765\n",
      "Epoch 10/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0120 - val_accuracy: 0.9799 - val_loss: 0.0736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30e1bcfa0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义 MLP 模型，使用 functional API\n",
    "inputs = tf.keras.layers.Input(shape=(input_size, ))\n",
    "x = tf.keras.layers.Dense(hidden_size1, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(hidden_size2, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(output_size, activation='softmax')(x)\n",
    "\n",
    "model3 = tf.keras.Model(inputs, outputs)\n",
    "model3.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()\n",
    "\n",
    "model3.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8848c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_93\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_93\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_95 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_22 (\u001b[38;5;33mMLP\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │       \u001b[38;5;34m235,146\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.7962 - val_accuracy: 0.9465 - val_loss: 0.1843\n",
      "Epoch 2/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1656 - val_accuracy: 0.9650 - val_loss: 0.1187\n",
      "Epoch 3/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1050 - val_accuracy: 0.9712 - val_loss: 0.0976\n",
      "Epoch 4/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0739 - val_accuracy: 0.9763 - val_loss: 0.0795\n",
      "Epoch 5/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0595 - val_accuracy: 0.9764 - val_loss: 0.0745\n",
      "Epoch 6/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0437 - val_accuracy: 0.9730 - val_loss: 0.0857\n",
      "Epoch 7/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0348 - val_accuracy: 0.9775 - val_loss: 0.0707\n",
      "Epoch 8/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0270 - val_accuracy: 0.9790 - val_loss: 0.0710\n",
      "Epoch 9/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0218 - val_accuracy: 0.9804 - val_loss: 0.0668\n",
      "Epoch 10/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0149 - val_accuracy: 0.9793 - val_loss: 0.0751\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.9758 - loss: 0.0923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07508836686611176, 0.9793000221252441]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_size = 784  # 输入维度（例如28x28图像）\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "output_size = 10  # 输出类别数\n",
    "\n",
    "# 自定义一个全连接层\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # 定义权重和偏置\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[-1], self.units),\n",
    "                                      initializer='random_normal')\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.units,),\n",
    "                                    initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # 前向传播计算\n",
    "        z = tf.matmul(inputs, self.kernel) + self.bias\n",
    "        if self.activation:\n",
    "            return self.activation(z)\n",
    "        return z\n",
    "\n",
    "# 定义模型\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = MyDenseLayer(hidden_size1, activation=tf.nn.relu)\n",
    "        self.layer2 = MyDenseLayer(hidden_size2, activation=tf.nn.relu)\n",
    "        self.layer3 = MyDenseLayer(output_size)  # 输出层没有激活函数（适用于分类任务）\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        return self.layer3(x)\n",
    "\n",
    "# 创建模型实例\n",
    "model = MLP()\n",
    "\n",
    "# 创建输入层并定义输入形状\n",
    "inputs = tf.keras.Input(shape=(input_size,))\n",
    "outputs = model(inputs)\n",
    "\n",
    "# 创建模型\n",
    "model4 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# 编译模型\n",
    "model4.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# 输出模型结构\n",
    "model4.summary()\n",
    "\n",
    "model4.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test))\n",
    "\n",
    "model4.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
